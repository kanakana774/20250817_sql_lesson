### PostgreSQL 実行計画と SQL の理解を深める

SQL のパフォーマンスチューニングやデバッグにおいて、PostgreSQL の「実行計画」は非常に強力なツールです。しかし、実行計画を正しく読み解くには、SQL の「論理実行順序」とデータベースオプティマイザの「物理実行順序（最適化）」という二つの異なる視点を理解する必要があります。

#### 1. SQL の論理実行順序：結果を予測するための設計図

SQL は宣言型言語であり、「何をしたいか」を記述します。その「何をしたいか」がどのような順序で処理され、最終結果が導かれるかを概念的に示したのが「論理実行順序」です。これは SQL を書く人がクエリの振る舞いや結果を予測するための**設計図**となります。

一般的なクエリの論理実行順序は以下の通りです。

1.  **FROM / JOIN**: 最初に、`FROM` 句で指定されたテーブルや `JOIN` 句によって結合されるテーブルが特定され、その結合結果が生成されます。
2.  **WHERE**: 結合された結果の行に対して、`WHERE` 句の条件が適用され、条件を満たさない行はここで除外されます。
3.  **GROUP BY**: `WHERE` 句で絞り込まれた行が、`GROUP BY` 句で指定されたカラムに基づいてグループ化されます。
4.  **HAVING**: グループ化された各グループに対して、`HAVING` 句の条件が適用され、条件を満たさないグループはここで除外されます。`HAVING` は集約関数に対するフィルタリングです。
5.  **SELECT**: `HAVING` 句を通過したグループ（またはグループ化されていない行）に対して、`SELECT` 句で指定されたカラムや集約関数が評価され、最終的な出力カラムが形成されます。この段階で、`SELECT` 句で定義された別名（エイリアス）が有効になります。
6.  **DISTINCT**: `SELECT` 句で生成された結果セットから、重複する行が除外されます。
7.  **ORDER BY**: 重複が除外された（または除外されなかった）結果セットが、`ORDER BY` 句で指定されたカラムに基づいてソートされます。
8.  **LIMIT / OFFSET**: ソートされた結果セットから、`LIMIT` で指定された行数だけが取得され、`OFFSET` で指定された行数はスキップされます。

**なぜこの論理実行順序が重要なのか？**

- **結果の予測**: クエリがどのような結果を返すかを正確に推測できます。
- **構文規則の理解**: なぜ `WHERE` 句で集約関数を使えないのか、なぜ `HAVING` 句で `SELECT` 句の別名を使えないのか、といった SQL の構文規則の理由を理解できます。

**具体例：論理実行順序の適用**

**テーブル定義:**

```sql
CREATE TABLE products (
    product_id SERIAL PRIMARY KEY,
    product_name VARCHAR(100),
    category VARCHAR(50),
    price NUMERIC(10, 2)
);

CREATE TABLE sales (
    sale_id SERIAL PRIMARY KEY,
    product_id INT REFERENCES products(product_id),
    sale_date DATE,
    quantity INT,
    total_amount NUMERIC(10, 2)
);

-- サンプルデータ挿入 (一部抜粋)
INSERT INTO products (product_name, category, price) VALUES
('Laptop', 'Electronics', 1200.00),
('Mouse', 'Electronics', 25.00),
('Keyboard', 'Electronics', 75.00),
('Desk Chair', 'Furniture', 150.00),
('Coffee Table', 'Furniture', 80.00);

INSERT INTO sales (product_id, sale_date, quantity, total_amount) VALUES
(1, '2023-01-05', 1, 1200.00),
(2, '2023-01-05', 2, 50.00),
(1, '2023-01-10', 1, 1200.00),
(3, '2023-01-12', 1, 75.00),
(4, '2023-01-15', 1, 150.00),
(2, '2023-01-20', 3, 75.00);
```

**クエリ:**
「価格が 100 ドル以上の商品について、各カテゴリごとの総販売数をカウントし、それが 2 件以上のカテゴリのみを表示し、販売数が多い順にソートする。ただし、上位 3 件まで。」

```sql
SELECT
    p.category,
    COUNT(s.sale_id) AS total_sales_count
FROM
    products p
JOIN
    sales s ON p.product_id = s.product_id
WHERE
    p.price >= 100.00
GROUP BY
    p.category
HAVING
    COUNT(s.sale_id) >= 2
ORDER BY
    total_sales_count DESC
LIMIT 3;
```

**論理実行順序での思考プロセス:**

1.  **FROM / JOIN**:

    - `products` と `sales` テーブルを `product_id` で結合します。
    - この時点では、すべての商品と販売の組み合わせが中間結果として生成されます。
      - 例: Laptop - Sale1, Mouse - Sale2, Laptop - Sale3, Keyboard - Sale4, Desk Chair - Sale5, Mouse - Sale6

2.  **WHERE**:

    - 結合結果から `p.price >= 100.00` の条件を満たす行を抽出します。
      - Mouse (price 25) の販売はここで除外されます。
      - 中間結果: Laptop - Sale1, Laptop - Sale3, Keyboard - Sale4, Desk Chair - Sale5

3.  **GROUP BY**:

    - `WHERE` を通過した行を `p.category` でグループ化します。
      - Electronics グループ: (Laptop - Sale1, Laptop - Sale3, Keyboard - Sale4)
      - Furniture グループ: (Desk Chair - Sale5)

4.  **HAVING**:

    - 各グループに対して `COUNT(s.sale_id) >= 2` の条件を適用します。
      - Electronics グループ: `COUNT(s.sale_id)` は 3。条件を満たすので残る。
      - Furniture グループ: `COUNT(s.sale_id)` は 1。条件を満たさないので除外される。
      - 中間結果: Electronics グループのみ

5.  **SELECT**:

    - 残ったグループに対して、`p.category` と `COUNT(s.sale_id)` を評価し、別名 `total_sales_count` を付けます。
      - 結果: `category='Electronics', total_sales_count=3`
        - ⇒ 集計関数は、そのグループの中の代表値をピックする役割。グループ内で同値のものは代表値をピックする必要がない。（group by のキーになってるものや、固定値）

6.  **DISTINCT**: （このクエリにはないためスキップ）

7.  **ORDER BY**:

    - `total_sales_count` を降順 (`DESC`) でソートします。
      - この例では 1 行しかないのでソートは実質意味をなしませんが、複数行あればソートされます。

8.  **LIMIT / OFFSET**:
    - 上位 3 件を抽出します。
      - 最終結果: `category='Electronics', total_sales_count=3`

このように、論理実行順序で段階的に考えることで、最終的な結果を正確に導き出すことができます。

---

#### 2. PostgreSQL 実行計画 (物理実行順序)：データベースの最適化戦略

SQL の論理実行順序が「何をしたいか」の設計図であるのに対し、PostgreSQL の実行計画は「**データベースがそれをどのように、最も効率的に実現するか**」という**物理的な実装戦略**を示します。データベースのオプティマイザは、論理的な結果を変えることなく、最も低いコストでクエリを実行するための最適な手順を決定します。

実行計画は、`EXPLAIN SQL文;` または `EXPLAIN ANALYZE SQL文;` で取得できます。特に `EXPLAIN ANALYZE` は実際の実行時間を伴うため、パフォーマンスチューニングには不可欠です。

**実行計画の主要な要素と読み方:**

- **ツリー構造**: 実行計画はツリー形式で表示され、通常は**リーフノード（下部）からルートノード（上部）へ、または右から左へ**処理が進みます。
- **ノードタイプ**: 各行は特定の操作（`Seq Scan`, `Index Scan`, `Hash Join`, `Sort`, `Aggregate` など）を示します。
- **Cost (コスト)**: `(startup cost..total cost)` の形式で、推定コストが表示されます。
  - `startup cost`: 最初の 1 行が返されるまでの推定コスト。
  - `total cost`: 全ての行が返されるまでの推定コスト。
  - これはあくまで推定値であり、ディスクページ読み込み 1 回を基準とした相対的な値です。
- **Rows (行数)**: ノードが出力すると推定される行数。`EXPLAIN ANALYZE` では `actual rows` (実際の行数) も表示されます。
- **Width (幅)**: ノードが出力する行の平均バイト幅。
- **Time (時間)** ( `EXPLAIN ANALYZE` のみ): `actual time=開始時間..終了時間` で、ノードの実際の実行時間（ミリ秒）が表示されます。`loops=回数` は、このノードが何回実行されたかを示します（特に相関サブクエリなどで重要）。
- **Filter / Index Cond**: `WHERE` 句や `JOIN` 句の条件がどこで適用されているかを示します。`Index Cond` はインデックスを使って条件を絞り込んでいることを意味します。
- **Buffers**: `EXPLAIN (ANALYZE, BUFFERS)` で詳細なバッファ使用状況（共有バッファのヒット率、ディスク I/O など）を確認できます。

**具体例：先ほどのクエリの実行計画**

上記の「価格が 100 ドル以上の商品について...」のクエリを `EXPLAIN ANALYZE` してみましょう。

```sql
EXPLAIN ANALYZE
SELECT
    p.category,
    COUNT(s.sale_id) AS total_sales_count
FROM
    products p
JOIN
    sales s ON p.product_id = s.product_id
WHERE
    p.price >= 100.00
GROUP BY
    p.category
HAVING
    COUNT(s.sale_id) >= 2
ORDER BY
    total_sales_count DESC
LIMIT 3;
```

`

```
                                                        QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=19.46..19.46 rows=1 width=38) (actual time=0.088..0.089 rows=1 loops=1)
   ->  Sort  (cost=19.46..19.47 rows=1 width=38) (actual time=0.087..0.087 rows=1 loops=1)
         Sort Key: (count(s.sale_id)) DESC
         Sort Method: quicksort  Memory: 25kB
         ->  HashAggregate  (cost=19.44..19.45 rows=1 width=38) (actual time=0.078..0.078 rows=1 loops=1)
               Group Key: p.category
               Filter: (count(s.sale_id) >= 2)
               ->  Hash Join  (cost=3.70..19.43 rows=6 width=38) (actual time=0.033..0.066 rows=4 loops=1)
                     Hash Cond: (s.product_id = p.product_id)
                     ->  Seq Scan on sales s  (cost=0.00..15.50 rows=550 width=8) (actual time=0.003..0.012 rows=6 loops=1)
                     ->  Hash  (cost=3.68..3.68 rows=2 width=34) (actual time=0.024..0.024 rows=3 loops=1)
                           Buckets: 1024  Batches: 1  Memory Usage: 9kB
                           ->  Seq Scan on products p  (cost=0.00..3.68 rows=2 width=34) (actual time=0.001..0.015 rows=3 loops=1)
                                 Filter: (price >= 100.00)
                                 Rows Removed by Filter: 2
 Planning Time: 0.170 ms
 Execution Time: 0.117 ms
(16 rows)
```

**実行計画の読み解きと論理実行順序との比較:**

1.  **物理実行の開始 (下から上へ):**

    - **`Seq Scan on products p`**: まず `products` テーブル全体をスキャンします。
    - **`Filter: (price >= 100.00)`**: スキャン中に `p.price >= 100.00` の条件を適用し、価格が 100 ドル未満の商品はここで除外されます。
      - **注目点**: これは論理実行順序では `JOIN` の後に来る `WHERE` 句の条件ですが、オプティマイザは `products` テーブル単独で評価できるため、`JOIN` の**前**にこのフィルタリングを実行しています（述語のプッシュダウン）。これにより、後続の `JOIN` に渡される行数が減り、効率が上がります。
    - **`Hash`**: フィルタリングされた `products` の結果（3 行）を使ってハッシュテーブルを作成します。これは `Hash Join` の準備です。

2.  **`Seq Scan on sales s`**: `sales` テーブル全体をスキャンします。

3.  **`Hash Join`**: `sales` テーブルの各行と、`products` のハッシュテーブルを `s.product_id = p.product_id` の条件で結合します。

4.  **`HashAggregate`**: `Hash Join` の結果に対して、`Group Key: p.category` に基づいてグループ化を行い、同時に `COUNT(s.sale_id)` の集計を計算します。

    - **注目点**: `Filter: (count(s.sale_id) >= 2)` は、論理実行順序では `HAVING` 句の条件であり、`Aggregate` ノード内で処理されています。ここでも `SELECT` 句の別名 `total_sales_count` は使われておらず、直接集約関数が書かれています。

5.  **`Sort`**: `HashAggregate` の結果を `count(s.sale_id) DESC` でソートします。これは `ORDER BY total_sales_count DESC` に対応します。

6.  **`Limit`**: ソートされた結果の上位 3 行を取得します。

**重要な比較ポイント:**

- **論理実行順序は SQL のセマンティクス（意味）を定義する**: ユーザーは「まず結合して、次に WHERE で絞って、それから GROUP BY と HAVING でフィルタリングし、最後に SELECT と ORDER BY と LIMIT」という思考で SQL を書く。
- **物理実行順序（実行計画）はパフォーマンスを最大化する**: データベースは、同じ最終結果を得るために、論理的な順序を崩してでも「WHERE 句の条件をできるだけ早く適用する」「効率の良い結合方法を選ぶ」といった最適化を行う。

この例では、`products.price >= 100.00` のフィルタリングが `JOIN` の前に処理されることで、中間結果のサイズが大幅に減少し、クエリ全体の効率が向上しています。

---

#### 3. サブクエリの論理実行順序とオプティマイザの振る舞い

サブクエリは、クエリの中に別のクエリを埋め込むことで、複雑なロジックを表現します。その論理実行順序はサブクエリの種類によって異なりますが、オプティマイザはここでも最適化を試みます。

##### a. 非相関サブクエリ (Non-correlated Subquery)

- **定義**: 内側のサブクエリが、外側のクエリのどの行にも依存しないサブクエリです。内側のクエリは一度だけ実行され、その結果が外側のクエリに渡されます。
- **論理実行順序**:
  1.  **内側のサブクエリが完全に評価され、一時的な結果セット（テーブル、スカラ値、リストなど）を生成する。**
  2.  **外側のクエリが、この一時的な結果セットを利用して評価される。**
- **具体例**: 「平均価格以上の商品のリスト」

  ```sql
  SELECT product_name, price
  FROM products
  WHERE price > (SELECT AVG(price) FROM products); -- 非相関サブクエリ
  ```

  **論理的思考:**

  1.  まず `(SELECT AVG(price) FROM products)` が評価され、`products` テーブル全体の平均価格（例: 506.00）が計算される。
  2.  次に、外側のクエリ `SELECT product_name, price FROM products WHERE price > 506.00` が実行される。
      - Laptop (1200.00) は条件を満たす。
      - Mouse (25.00) は条件を満たさない。
      - ...

  **オプティマイザの振る舞い:** 通常、オプティマイザもこの論理順序に近い形で実行します。サブクエリの結果を一度計算してキャッシュし、外側のクエリで利用します。

##### b. 相関サブクエリ (correlated Subquery)

相関サブクエリは、**外側のクエリの「どこかの句」で条件や値を計算するために利用される**ため、その「どこかの句」の論理実行順序に従って評価がトリガーされます。

基本は「外側の FROM によって選ばれた各行に対して、サブクエリが評価される」という枠組みです。

###### 1. `SELECT` 句内の相関サブクエリ (スカラーサブクエリ)

**論理実行順序への組み込み方:**

1.  外側のクエリの `FROM / JOIN` によって行が生成される。
2.  外側のクエリの `WHERE` 句が評価される。
3.  外側のクエリの `GROUP BY` が評価される。
4.  外側のクエリの `HAVING` が評価される。
5.  **外側のクエリの `SELECT` 句が評価される際に、その行のデータ（例: `u.id`）を使い、相関サブクエリが実行される。**
    - サブクエリ内では、`FROM` → `WHERE` → `GROUP BY` → `HAVING` → `SELECT` の論理順序が、外側の行から渡された値を使って実行される。
    - サブクエリは 1 つのスカラ値（単一の値）を返す必要がある。
6.  サブクエリの結果が、外側の `SELECT` 句のそのカラムの値となる。
7.  外側のクエリの `DISTINCT`、`ORDER BY`、`LIMIT` が続く。

**具体例:** 各ユーザーの最新の注文日を取得する

```sql
SELECT u.id, u.name,
       (SELECT MAX(o.order_date) -- (5) SELECT句内でサブクエリが評価される
        FROM orders o
        WHERE o.user_id = u.id -- 内側WHERE: 外側u.idを参照
       ) AS latest_order_date
FROM users u; -- (1) FROM
```

###### 2. `WHERE` 句内の相関サブクエリ

**論理実行順序への組み込み方:**

1.  外側のクエリの `FROM / JOIN` によって行が生成される。
2.  **外側のクエリの `WHERE` 句が評価される際に、その行のデータ（例: `u.id`）を使い、相関サブクエリが実行される。**
    - サブクエリ内では、`FROM` → `WHERE` → `GROUP BY` → `HAVING` → `SELECT` の論理順序が、外側の行から渡された値を使って実行される。
    - サブクエリの結果が、`WHERE` 句の条件（例: `IN`, 比較演算子）に適用される。
3.  `WHERE` 句の条件に基づいて、現在の外側の行を残すか破棄するかが決定される。
4.  外側のクエリの `GROUP BY`、`HAVING`、`SELECT` などが続く。

**具体例:** 平均より高額な注文をしたユーザーのリスト (ユーザーごとの平均注文額と比較)

```sql
SELECT u.name
FROM users u -- (1) FROM
WHERE (SELECT AVG(o.total_amount) -- (2) 外側WHERE句の条件でサブクエリが評価される
       FROM orders o
       WHERE o.user_id = u.id -- 内側WHERE: 外側u.idを参照
      ) > (SELECT AVG(total_amount) FROM orders); -- 非相関サブクエリ (これは外側WHERE評価前に一度だけ評価される)
```

###### 3. `HAVING` 句内の相関サブクエリ

**論理実行順序への組み込み方:**

1.  外側のクエリの `FROM / JOIN`、`WHERE` が評価される。
2.  外側のクエリの `GROUP BY` によってグループが形成される。
3.  **外側のクエリの `HAVING` 句が評価される際に、その**グループのデータ（例: `u.category`）**を使い、相関サブクエリが実行される。**
    - サブクエリ内では、`FROM` → `WHERE` → `GROUP BY` → `HAVING` → `SELECT` の論理順序が、外側のグループから渡された値を使って実行される。
    - サブクエリの結果が、`HAVING` 句の条件に適用される。
4.  `HAVING` 句の条件に基づいて、現在のグループを残すか破棄するかが決定される。
5.  外側のクエリの `SELECT`、`DISTINCT`、`ORDER BY`、`LIMIT` が続く。

**具体例:** 各カテゴリの販売総額が、そのカテゴリ内で最も売れた商品の単価より高いカテゴリを抽出（あまり現実的ではないが例として）

```sql
SELECT p.category, SUM(s.total_amount) AS category_total_sales
FROM products p
JOIN sales s ON p.product_id = s.product_id
GROUP BY p.category -- (3) GROUP BY
HAVING SUM(s.total_amount) > ( -- (4) HAVING句の条件でサブクエリが評価される
    SELECT MAX(p_inner.price)
    FROM products p_inner
    WHERE p_inner.category = p.category -- 内側WHERE: 外側p.categoryを参照
);
```

###### 4. `EXISTS` / `NOT EXISTS` 句

`EXISTS` / `NOT EXISTS` は、上記の `WHERE` 句や `HAVING` 句内の相関サブクエリの一種です。特に `WHERE` 句でよく使われます。

**論理実行順序への組み込み方:**

1.  外側のクエリの `FROM / JOIN` によって行が生成される。
2.  **外側のクエリの `WHERE` 句が評価される際に、その行のデータ（例: `u.id`）を使い、`EXISTS` サブクエリが実行される。**
    - サブクエリ内は通常の論理実行順序で評価されるが、**最初の 1 行が見つかった時点でそれ以上の検索を停止**する（ショートサーキット）。
    - サブクエリの `SELECT` リストは `SELECT 1` などで十分であり、内容には意味がない。
    - サブクエリが 1 行でも返せば `TRUE`、返さなければ `FALSE` を返す。
3.  `WHERE` 句の条件（`TRUE` or `FALSE`）に基づいて、現在の外側の行を残すか破棄するかが決定される。
4.  外側のクエリの `GROUP BY`、`HAVING`、`SELECT` などが続く。

**具体例:** 注文が 1 件でもあるユーザーのリスト

```sql
SELECT u.name
FROM users u -- (1) FROM
WHERE EXISTS ( -- (2) 外側WHERE句の条件でEXISTSサブクエリが評価される
    SELECT 1
    FROM orders o
    WHERE o.user_id = u.id -- 内側WHERE: 外側u.idを参照
);
```

###### 結論：

相関サブクエリは、外側の論理実行順序のあるステップ（`SELECT`, `WHERE`, `HAVING` など）の中で、外側の行やグループのデータを参照しながら、**自身の内側でまた別の論理実行順序を回す**、というイメージで捉えると、常に正確にその挙動を予測できます。

---

### まとめとパフォーマンスチューニングへの応用

1.  **論理実行順序**:

    - **クエリの結果を正確に予測するための「設計図」**。これを理解していれば、SQL の構文規則や各句の役割が明確になります。
    - SQL の学習においては、まずこの論理実行順序で考えることが基本です。

2.  **物理実行順序 (実行計画)**:
    - **データベースがその設計図を「どのように、最も効率的に実現するか」を示す「実装詳細」**。
    - 論理実行順序を逸脱してでも、**コストを最小化するための最適化（述語のプッシュダウン、結合順序の変更、アルゴリズムの選択など）**を行います。
    - `EXPLAIN ANALYZE` を使って、実際のボトルネック（時間のかかっているノード、推定行数と実際の行数の大きな乖離、`Seq Scan` の多発など）を特定し、インデックスの追加、`WHERE` 句の改善、JOIN 順序の見直し、`Work_mem` の調整などでパフォーマンスを改善します。

この二つの視点を持ち、特にサブクエリの種類に応じた論理的な動きを理解しておくことで、複雑な SQL であってもその振る舞いを正確に把握し、必要に応じて最適なチューニング戦略を立てることができるようになります。

# チューニング

### PostgreSQL 実行計画によるパフォーマンス改善の実践的な手法

実行計画は、SQL のボトルネックを特定し、効果的なチューニングを行うための羅針盤です。闇雲にインデックスを追加したり、設定値を変更したりする前に、必ず実行計画を確認する習慣をつけましょう。

#### ステップ 1: ボトルネッククエリの特定

まず、システム全体でパフォーマンス上の問題を引き起こしているクエリを特定します。

- **長期実行クエリのモニタリング**: `pg_stat_activity` ビューや、APM (Application Performance Monitoring) ツールを使って、長時間実行されているクエリや頻繁に実行されるクエリを特定します。
- **ログの分析**: PostgreSQL のログ設定で、一定時間以上かかるクエリをログに出力するように設定し（`log_min_duration_statement`）、それを分析します。
- **再現性の確認**: 可能であれば、問題を再現できる最小限のデータセットと環境を用意します。

#### ステップ 2: `EXPLAIN ANALYZE` の取得と基本的な確認 ★

特定したクエリに対して、`EXPLAIN ANALYZE` を実行します。`BUFFERS` オプションも追加すると、ディスク I/O に関する詳細もわかり、さらに分析が深まります。

```sql
EXPLAIN (ANALYZE, VERBOSE, BUFFERS) YOUR_SQL_STATEMENT;
```

**基本的な確認ポイント:**

1.  **`Execution Time`**: クエリ全体の実行時間。これが問題視している時間と一致しているか確認します。
2.  **`Planning Time`**: クエリの実行計画を生成するのにかかった時間。これが異常に長い場合、統計情報が古すぎるか、非常に複雑なクエリである可能性があります。
3.  **一番時間のかかっているノードの特定**: 実行計画の各ノードの `actual time` を見て、最も時間がかかっているノード（ホットスポット）を見つけます。チューニングの優先順位はここに集中します。
4.  **`rows` (推定) vs `actual rows` (実際) の乖離**:
    - この乖離が大きい場合、オプティマイザの統計情報が不正確である可能性が高いです。統計情報が古いと、オプティマイザが間違った実行計画を選択してしまいます。

⇒ とはいったものの実際に実務で巨大テーブルを扱う場合、だいたい index なしで検索されてないかチェックすることがほとんどかと思いますので、まずは Seq Scan が発生してる箇所をなんとか index を使ったクエリに変えられないか見ることになると思います。ちなみに、index は勝手に作ったりとかはできないと思うので、どうしてもパフォーマンスが悪い際に index を張るか偉い人と相談みたいな感じになるかと思います。なのでまずはパフォーマンス悪そうだなを見つけられるようになることがここでの目標です。

#### ステップ 3: ボトルネックノードの種類に応じた詳細分析と対策

最も時間のかかっているノードを特定したら、そのノードの種類に応じて具体的な対策を検討します。

##### 3.1. スキャン操作 (`Seq Scan`, `Index Scan`, `Bitmap Heap Scan`) がボトルネックの場合

- **`Seq Scan` がボトルネック (`actual time` が長い) の場合**:
  - **原因**: テーブル全体をスキャンしているため。`WHERE` 句や `JOIN` 句の条件で効率的に行を絞り込めていない。
  - **対策**:
    - **インデックスの追加**: `WHERE` 句や `JOIN` 句で使われているカラムに適切なインデックス（`B-tree` が一般的）を作成します。
      ```sql
      CREATE INDEX idx_table_column ON your_table (column_name);
      ```
    - **複合インデックス**: 複数のカラムで絞り込んでいる場合（例: `WHERE column1 = ? AND column2 = ?`）、複合インデックスを検討します。
      ```sql
      CREATE INDEX idx_table_col1_col2 ON your_table (column1, column2);
      ```
      **注意**: 複合インデックスは、先頭のカラムから順に使われることに注意してください（左端プレフィックス規則）。
    - **`ANALYZE` の実行**: インデックスを作成・削除した場合、必ず `ANALYZE your_table;` を実行して統計情報を更新します。
    - **条件の見直し**: `WHERE` 句の条件がインデックスを使えない形になっていないか確認します（例: `column + 1 = ?`, `LOWER(column) = ?` など。関数を使っているとインデックスが使えないことが多い）。
      - **対策**: 関数インデックス (Function Index) を検討する。
        ```sql
        CREATE INDEX idx_table_lower_column ON your_table (LOWER(column_name));
        ```
- **`Index Scan` や `Bitmap Heap Scan` の `actual time` が長い場合**:
  - **原因**: インデックス自体は使われているが、依然としてコストが高い。
    - **大量の行を取得している**: インデックスで絞り込んでも、結局大量の行が返され、その都度テーブルヒープへのアクセスが発生している。
    - **`Index Only Scan` になっていない**: `SELECT` 句にインデックスに含まれていないカラムがあり、テーブルヒープへのアクセス（visibility map の確認も含む）が発生している。
  - **対策**:
    - **インデックスの改善 (Index Only Scan 狙い)**: `SELECT` 句で取得したいカラムがインデックスに含まれていない場合、`INCLUDE` 句でインデックスに追加することを検討します。これにより、テーブルヒープへのアクセスを減らせる可能性があります（ただし、インデックスサイズが大きくなるトレードオフ）。
      ```sql
      CREATE INDEX idx_table_col1_incl_col2 ON your_table (column1) INCLUDE (column2);
      ```
    - **取得行数の削減**: そもそも、本当にそんなに多くの行が必要なのか？ `LIMIT` 句を追加したり、アプリケーション側で必要なデータのみをフェッチするように見直します。
    - **Partial Index**: 特定の条件に合致するデータが少ない場合、その条件でフィルタリングされた部分的なインデックスを作成することで、インデックスサイズを小さくし、検索効率を高めます。
      ```sql
      CREATE INDEX idx_table_status_active ON your_table (column_name) WHERE status = 'active';
      ```
- **`Buffers` 情報の活用**:
  - `shared hit`: 共有バッファからの読み込みヒット数。これが高いほどメモリ内で処理が完結しており高速です。
  - `shared read`: 共有バッファに存在せず、ディスクから読み込まれた回数。これが高い場合、I/O がボトルネックの可能性があります。`shared_buffers` の設定を見直したり、キャッシュヒット率が低い原因を探ります。
  - `temp read`/`temp write`: 一時ファイルへの読み書き。これが高い場合、メモリが足りずディスクにスピルしていることを意味します。`work_mem` の設定を見直します。

##### 3.2. 結合操作 (`Hash Join`, `Nested Loop Join`, `Merge Join`) がボトルネックの場合

- **`actual time` が長い結合ノードの特定**:
  - **`Hash Join` が遅い場合**:
    - **原因**: ハッシュテーブルの構築に時間がかかっている（`Hash` ノードの `actual time` を確認）。または、ハッシュテーブルがメモリに収まらず、ディスクにスピルしている（`temp write` が多い）。
    - **対策**:
      - **`work_mem` の増強**: `work_mem` の設定値を増やし、ハッシュテーブルがメモリ内に収まるようにします。
      - **結合順序の最適化**: 結合するテーブルの順序をオプティマイザが間違えている可能性。小さいテーブルを先にハッシュビルド側に持ってくるのが理想。
      - **前段のスキャン・フィルタリングの改善**: 結合に渡される行数を減らすことで、ハッシュテーブルのサイズが小さくなり、高速化されます。
  - **`Nested Loop Join` が遅い場合**:
    - **原因**: 外部テーブルの各行に対して、内部テーブルが効率的に検索できていない。内部テーブルに適切なインデックスがない。
    - **対策**:
      - **内部テーブルにインデックス**: 内部テーブル（`loops` 数が多く、かつ `actual time` が長い側のノード）の結合キーにインデックスを作成します。
      - **結合順序の確認**: 外部テーブルの行数が少なく、内部テーブルにインデックスが効くように結合順序になっているか確認します。
      - **前段のスキャン・フィルタリングの改善**: 外部テーブルの行数を減らすことで、内部ループの実行回数が減ります。
  - **`Merge Join` が遅い場合**:
    - **原因**: 結合前にソートが必要な場合、そのソートに時間がかかっている。
    - **対策**:
      - **ソートの回避**: 結合キーにインデックスがあり、それがソート済みデータとして利用できる場合はソートが省略されます。インデックスの追加を検討します。
      - **`work_mem` の増強**: ソートがメモリ内で完結するように `work_mem` を調整します。

##### 3.3. ソート操作 (`Sort`) がボトルネックの場合

- **`actual time` が長い `Sort` ノードの特定**:
  - **原因**: `ORDER BY`, `GROUP BY`, `DISTINCT` などによってソートが必要になっている。ソート対象のデータ量が多すぎる。メモリに収まらずディスクにスピルしている。
  - **対策**:
    - **`work_mem` の増強**: ソートがメモリ内で完結するように `work_mem` の設定値を増やします。`Sort Method: external merge` と表示されている場合、メモリ不足でディスクに書き出しています。
    - **インデックスの利用**: `ORDER BY` 句で使われているカラムにインデックスを作成することで、ソート処理をインデックススキャンで代替できる場合があります。複合インデックスの場合、`ORDER BY` のカラム順がインデックス順と一致している必要があります。
      ```sql
      CREATE INDEX idx_table_col_order ON your_table (column_name DESC);
      ```
    - **ソート対象の削減**: 前段の `WHERE` 句などでデータを絞り込み、ソート対象の行数を減らします。
    - **`LIMIT` の活用**: `LIMIT` 句が使われている場合、`Sort Method: top-N heapsort` となっていれば、PostgreSQL は効率的なアルゴリズムを使用しています。

##### 3.4. 集約操作 (`Aggregate`, `HashAggregate`) がボトルネックの場合

- **`actual time` が長い `Aggregate` ノードの特定**:
  - **原因**: 集約対象のデータ量が多い。`GROUP BY` のキーが多く、ハッシュテーブルの構築に時間がかかっている。
  - **対策**:
    - **前段のフィルタリングの改善**: `WHERE` 句で集約対象の行数を減らします。
    - **`work_mem` の増強**: `HashAggregate` の場合、ハッシュテーブルがメモリ内で完結するように `work_mem` を調整します。
    - **`GROUP BY` キーの見直し**: 必要なキーのみに絞り込むことを検討します。

#### ステップ 4: 統計情報の更新

`rows` と `actual rows` の乖離が大きい場合は、オプティマイザの判断材料となる統計情報が古いため、必ず `ANALYZE` を実行します。テーブルのデータが頻繁に更新される場合は、定期的な `ANALYZE` や `VACUUM ANALYZE` の実行が重要です。

```sql
ANALYZE your_table_name; -- 特定のテーブル
ANALYZE; -- 全データベース
```

#### ステップ 5: 設定パラメータの調整

`postgresql.conf` ファイルで、上記で言及したようなパラメータを調整します。変更後は PostgreSQL の再起動（または `pg_reload_conf()`）が必要です。

- `shared_buffers`: PostgreSQL が共有メモリで使用するバッファサイズ。ディスク I/O が多い場合に検討。
- `work_mem`: ソート、ハッシュ、マージジョインなどの操作でプライベートに使用されるメモリ量。`external merge` や `temp write` が多い場合に検討。
- `maintenance_work_mem`: `VACUUM`, `CREATE INDEX`, `ALTER TABLE` などで使われるメモリ量。インデックス作成が遅い場合に検討。
- `random_page_cost`, `cpu_tuple_cost` など: オプティマイザのコスト計算モデルに影響を与えるパラメータ。通常はデフォルトで問題ないが、特殊な環境（SSD 環境など）では調整を検討。

#### ステップ 6: SQL の書き換え

データベース側のチューニングだけでなく、SQL の書き方自体を見直すことも重要です。

- **`SELECT *` の回避**: 必要なカラムのみを選択します。
- **不必要な `JOIN` の回避**: 不要なテーブルとの結合を削除します。
- **サブクエリの結合への書き換え**: 特に相関サブクエリは、適切にインデックスが効いていないと効率が悪くなりがちです。多くの場合、`JOIN` や `LATERAL JOIN` に書き換えることでパフォーマンスが向上します。
  - **例:** `WHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id)` は、`INNER JOIN orders o ON u.id = o.user_id` と `DISTINCT` の組み合わせで書き換えられることが多いです。

#### ステップ 7: 繰り返しと検証

パフォーマンスチューニングは一度で終わるものではありません。

1.  変更を適用する。
2.  再度 `EXPLAIN ANALYZE` を取得し、効果を確認する。
3.  ベンチマークや実際のアプリケーションでパフォーマンス改善が確認できるまで、ステップ 2〜6 を繰り返します。
4.  変更は一度に一つずつ行い、効果を測定することが重要です。

---
